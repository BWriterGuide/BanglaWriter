{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gaxBcQQKxx5f",
        "1fbRus3DycJh",
        "cH4G2tdDym5a",
        "mPY0pDhM6uoA"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habibsifat/User-Friendly-Bangla-Writer-A-Deep-Learning-Based-Approach/blob/master/Predict_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk_ncvpXx6S-",
        "colab_type": "code",
        "outputId": "16e5ae42-2436-4704-9acb-4c3f873cc6c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaxBcQQKxx5f",
        "colab_type": "text"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PDka5JRxqKn",
        "colab_type": "code",
        "outputId": "864af6fc-0137-40ec-99fc-40e03d60aa70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "__author__ = 'maxim'\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import string\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.utils.data_utils import get_file"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fbRus3DycJh",
        "colab_type": "text"
      },
      "source": [
        "# Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFjhShi0yJoK",
        "colab_type": "code",
        "outputId": "203ebd01-0180-43b1-bb02-e8ea04da5c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls 'drive/My Drive/Colab Notebooks/Capstone/Final/final_corpus.txt'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'drive/My Drive/Colab Notebooks/Capstone/Final/final_corpus.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mcuoqlbmymG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_file = 'drive/My Drive/Colab Notebooks/Capstone/Final/final_corpus.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTSUUiciyScT",
        "colab_type": "code",
        "outputId": "99977c6d-41b3-4acd-ec5a-1f30b196b7b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('\\nPreparing the  sentences...')\n",
        "sentences = []\n",
        "with open(corpus_file, 'r', encoding=\"utf-8-sig\") as f:\n",
        "    for line in f:\n",
        "        sentences.append(line.split())\n",
        "        \n",
        "print('Num sentences:', len(sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing the  sentences...\n",
            "Num sentences: 6476964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH4G2tdDym5a",
        "colab_type": "text"
      },
      "source": [
        "# W2V"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBBhjtjIJpcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQlmbFKQyYzC",
        "colab_type": "code",
        "outputId": "e16a7348-29a3-4ea5-aca3-22e379bf6a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print('\\nTraining word2vec...')\n",
        "word_model = Word2Vec(sentences, size=300, min_count=1, window=5, iter=100)\n",
        "pretrained_weights = word_model.wv.syn0 \n",
        "vocab_size, emdedding_size = pretrained_weights.shape\n",
        "print('Result embedding shape:', pretrained_weights.shape)\n",
        "\n",
        "#Save partly trained model\n",
        "#word_model.save('w2v_model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training word2vec...\n",
            "Result embedding shape: (8789, 300)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3rWoJP3eUU5",
        "colab_type": "code",
        "outputId": "e797105a-aa80-4388-ea77-5254d0cdbbc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Save partly trained model\n",
        "model_path = 'drive/My Drive/Colab Notebooks/Capstone/Final/100_w2v_model.h5'\n",
        "word_model.save(model_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJG1bCAPyFr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRJnM8D2ykpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2idx(word):\n",
        "  return word_model.wv.vocab[word].index\n",
        "def idx2word(idx):\n",
        "  return word_model.wv.index2word[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEEDWoBuy0xr",
        "colab_type": "text"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu0xJiKbnqN-",
        "colab_type": "code",
        "outputId": "94fd1185-f02e-468e-fe8e-ec9c7a7b0db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls 'drive/My Drive/Colab Notebooks/Capstone/Clean_txt/All Lenth/lenth3.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'drive/My Drive/Colab Notebooks/Capstone/Clean_txt/All Lenth/lenth3.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNt3a_AwnbrC",
        "colab_type": "code",
        "outputId": "2b00ef2a-489e-46fd-812b-b54fdde7cf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "corpus_file = 'drive/My Drive/Colab Notebooks/Capstone/Clean_txt/All Lenth/lenth3.txt'\n",
        "print('\\nPreparing the sentences...')\n",
        "sentences = []\n",
        "with open(corpus_file, 'r', encoding=\"utf-8-sig\") as f:\n",
        "    for line in f:\n",
        "        sentences.append(line.split())\n",
        "print('Num sentences:', len(sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing the sentences...\n",
            "Num sentences: 4638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOUD_d96y6wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_sentence_len = 3\n",
        "print('\\nPreparing the data for LSTM...')\n",
        "x = np.zeros([len(sentences), max_sentence_len], dtype=np.int32)\n",
        "y = np.zeros([len(sentences)], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, word in enumerate(sentence[:-1]):\n",
        "    train_x[i, t] = word2idx(word)\n",
        "  train_y[i] = word2idx(sentence[-1])\n",
        "print('train_x shape:', train_x.shape)\n",
        "print('train_y shape:', train_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep3uCeNDm_Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.cross_validation import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_x,test_x,train_y,test_y = train_test_split(x,y,test_size=0.2,random_state=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP5F9aChzGnW",
        "colab_type": "code",
        "outputId": "41ad6588-e1a7-418b-a17e-201b9ca8a231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print('\\nTraining LSTM...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[pretrained_weights]))\n",
        "model.add(LSTM(units=512,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=512, return_sequences=False))\n",
        "model.add(Dense(units=vocab_size))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_x, train_y,batch_size=128,epochs=5,shuffle=True, validation_data=(test_x, test_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training LSTM...\n",
            "Train on 3710 samples, validate on 928 samples\n",
            "Epoch 1/5\n",
            "3710/3710 [==============================] - 4s 1ms/step - loss: 1.9530 - acc: 0.9655 - val_loss: 4.2551e-05 - val_acc: 1.0000\n",
            "Epoch 2/5\n",
            "3710/3710 [==============================] - 1s 248us/step - loss: 4.2585e-05 - acc: 1.0000 - val_loss: 4.2576e-05 - val_acc: 1.0000\n",
            "Epoch 3/5\n",
            "3710/3710 [==============================] - 1s 245us/step - loss: 4.2580e-05 - acc: 1.0000 - val_loss: 4.2571e-05 - val_acc: 1.0000\n",
            "Epoch 4/5\n",
            "3710/3710 [==============================] - 1s 250us/step - loss: 4.2588e-05 - acc: 1.0000 - val_loss: 4.2573e-05 - val_acc: 1.0000\n",
            "Epoch 5/5\n",
            "3710/3710 [==============================] - 1s 247us/step - loss: 4.2583e-05 - acc: 1.0000 - val_loss: 4.2583e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd90fb12160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO5xfjYn7GeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load  model\n",
        "from keras.models import load_model\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS4nScu-8v3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_sentence_len = 10\n",
        "corpus_file='drive/My Drive/Colab Notebooks/Capstone/Clean_txt/All Lenth/lenth10.txt'\n",
        "print('\\nPreparing the sentences...')\n",
        "sentences = []\n",
        "with open(corpus_file, 'r', encoding=\"utf-8-sig\") as f:\n",
        "    for line in f:\n",
        "        sentences.append(line.split())\n",
        "print('Num sentences:', len(sentences))\n",
        "\n",
        "print('\\nPreparing the data for LSTM...')\n",
        "train_x = np.zeros([len(sentences), max_sentence_len], dtype=np.int32)\n",
        "train_y = np.zeros([len(sentences)], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, word in enumerate(sentence[:-1]):\n",
        "    train_x[i, t] = word2idx(word)\n",
        "  train_y[i] = word2idx(sentence[-1])\n",
        "print('train_x shape:', train_x.shape)\n",
        "print('train_y shape:', train_y.shape)\n",
        "print('\\nTraining LSTM...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[pretrained_weights]))\n",
        "model.add(LSTM(units=emdedding_size,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=emdedding_size, return_sequences=False))\n",
        "model.add(Dense(units=vocab_size))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(train_x, train_y,\n",
        "          batch_size=128,\n",
        "          epochs=1,\n",
        "callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h32iHmueOj7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save partly trained model\n",
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preySilNzeLL",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBOrLz5xzgz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_next(text, num_generated=1):\n",
        "  word_idxs = [word2idx(word) for word in text.split()]\n",
        "  #print(word_idxs)\n",
        "  #Str1 = input(\"Enter word :\")\n",
        "  Str1 = \"অনেক\"\n",
        "  for i in range(num_generated):\n",
        "    prediction = model.predict(x=np.array(word_idxs)) #print dimension\n",
        "    max_word = prediction[-1].argsort()[-1:][::-1]\n",
        "    #print(max_word)\n",
        "    j=1\n",
        "    for idx in max_word:\n",
        "      word_idxs.append(idx)\n",
        "      Distance = levenshtein_ratio_and_distance(Str1,idx2word(idx))\n",
        "      Ratio = levenshtein_ratio_and_distance(Str1,idx2word(idx),ratio_calc = True)\n",
        "      #print(\"Max word %d : %s \" % (j,idx2word(idx)))\n",
        "      #print(\"Distance : %s And Ratio : %s \" % (Distance,Ratio))\n",
        "      j+=1\n",
        "    #print(word_idxs)\n",
        "  return ' '.join(idx2word(idx) for idx in word_idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3tuD8SO-zqb",
        "colab_type": "code",
        "outputId": "683c19e5-79af-4c1d-8843-2f42eb4dbdb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "  #print('\\n For Lenth-5 Generating text after epoch: %d' % epoch)\n",
        "  texts = [\n",
        "    '* তড়িৎ প্রকৌশল UNK ',\n",
        "      '* এটি UNK বাংলা '\n",
        "  ]\n",
        "  for text in texts:\n",
        "    sample = generate_next(text)\n",
        "    #print('%s -> %s' % (text, sample))\n",
        "\n",
        "model.fit(train_x, train_y,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4638/4638 [==============================] - 1s 121us/step - loss: 2.1538\n",
            "Epoch 2/10\n",
            "4638/4638 [==============================] - 1s 123us/step - loss: 2.1549\n",
            "Epoch 3/10\n",
            "4638/4638 [==============================] - 1s 122us/step - loss: 2.1610\n",
            "Epoch 4/10\n",
            "4638/4638 [==============================] - 1s 126us/step - loss: 2.1565\n",
            "Epoch 5/10\n",
            "4638/4638 [==============================] - 1s 123us/step - loss: 2.1565\n",
            "Epoch 6/10\n",
            "4638/4638 [==============================] - 1s 121us/step - loss: 2.1563\n",
            "Epoch 7/10\n",
            "4638/4638 [==============================] - 1s 125us/step - loss: 2.1565\n",
            "Epoch 8/10\n",
            "4638/4638 [==============================] - 1s 121us/step - loss: 2.1523\n",
            "Epoch 9/10\n",
            "4638/4638 [==============================] - 1s 122us/step - loss: 2.1561\n",
            "Epoch 10/10\n",
            "4638/4638 [==============================] - 1s 120us/step - loss: 2.1544\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 100)         54300     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 100)         80400     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 543)               54843     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 543)               0         \n",
            "=================================================================\n",
            "Total params: 269,943\n",
            "Trainable params: 269,943\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivJg5PifzkNj",
        "colab_type": "text"
      },
      "source": [
        "# Edit_Distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tw-Zy2_zjlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def levenshtein_ratio_and_distance(s, t, ratio_calc = False):\n",
        "    \"\"\" levenshtein_ratio_and_distance:\n",
        "        Calculates levenshtein distance between two strings.\n",
        "        If ratio_calc = True, the function computes the\n",
        "        levenshtein distance ratio of similarity between two strings\n",
        "        For all i and j, distance[i,j] will contain the Levenshtein\n",
        "        distance between the first i characters of s and the\n",
        "        first j characters of t\n",
        "    \"\"\"\n",
        "    # Initialize matrix of zeros\n",
        "    rows = len(s)+1\n",
        "    cols = len(t)+1\n",
        "    distance = np.zeros((rows,cols),dtype = int)\n",
        "\n",
        "    # Populate matrix of zeros with the indeces of each character of both strings\n",
        "    for i in range(1, rows):\n",
        "        for k in range(1,cols):\n",
        "            distance[i][0] = i\n",
        "            distance[0][k] = k\n",
        "\n",
        "    # Iterate over the matrix to compute the cost of deletions,insertions and/or substitutions    \n",
        "    for col in range(1, cols):\n",
        "        for row in range(1, rows):\n",
        "            if s[row-1] == t[col-1]:\n",
        "                cost = 0 # If the characters are the same in the two strings in a given position [i,j] then the cost is 0\n",
        "            else:\n",
        "                # In order to align the results with those of the Python Levenshtein package, if we choose to calculate the ratio\n",
        "                # the cost of a substitution is 2. If we calculate just distance, then the cost of a substitution is 1.\n",
        "                if ratio_calc == True:\n",
        "                    cost = 2\n",
        "                else:\n",
        "                    cost = 1\n",
        "            distance[row][col] = min(distance[row-1][col] + 1,      # Cost of deletions\n",
        "                                 distance[row][col-1] + 1,          # Cost of insertions\n",
        "                                 distance[row-1][col-1] + cost)     # Cost of substitutions\n",
        "    if ratio_calc == True:\n",
        "        # Computation of the Levenshtein Distance Ratio\n",
        "        Ratio = ((len(s)+len(t)) - distance[row][col]) / (len(s)+len(t))\n",
        "        return Ratio\n",
        "    else:\n",
        "        # print(distance) # Uncomment if you want to see the matrix showing how the algorithm computes the cost of deletions,\n",
        "        # insertions and/or substitutions\n",
        "        # This is the minimum number of edits needed to convert string a to string b\n",
        "        return \" {} \".format(distance[row][col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzxufpRMz2N6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Str1 = \"Apple Inc.\"\n",
        "Str2 = \"Apple Inc\"\n",
        "Distance = levenshtein_ratio_and_distance(Str1,Str2)\n",
        "print(Distance)\n",
        "Ratio = levenshtein_ratio_and_distance(Str1,Str2,ratio_calc = True)\n",
        "print(Ratio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoCJAtM45lmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install Levenshtein"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dewvex_Rz4E4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Levenshtein as lev\n",
        "Str1 = \"Apple Inc.\"\n",
        "Str2 = \"apple Inc\"\n",
        "Distance = lev.distance(Str1.lower(),Str2.lower()),\n",
        "print(Distance)\n",
        "Ratio = lev.ratio(Str1.lower(),Str2.lower())\n",
        "print(Ratio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPY0pDhM6uoA",
        "colab_type": "text"
      },
      "source": [
        "# Give Suggesion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8Ih-9Km8Xlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load  word_model\n",
        "from keras.models import load_model\n",
        "word_model = load_model('word_model.h5')\n",
        "#Load  model\n",
        "from keras.models import load_model\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-oU8J4-6y4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=1\n",
        "for idx in max_word:\n",
        "      word_idxs.append(idx)\n",
        "      print(\"Max word %s : %s \" % (i,idx2word(idx)))\n",
        "      i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz623jJB4bsz",
        "colab_type": "text"
      },
      "source": [
        "Fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geNbP-n84B14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fuzzywuzzy\n",
        "from fuzzywuzzy import fuzz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0CzAFZZ0VKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Str1 = \"Los Angeles Lakers\"\n",
        "Str2 = \"Lakers\"\n",
        "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
        "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
        "print(Ratio)\n",
        "print(Partial_Ratio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sJ_W0m5g1II",
        "colab_type": "text"
      },
      "source": [
        "# Paragraph Correction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGfgqbk5eE7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_next_para(text, str1,num_generated=1):\n",
        "  word_idxs = [word2idx(word) for word in text.split()]\n",
        "  #print(word_idxs)\n",
        "  #Str1 = input(\"Enter word :\")\n",
        "  #Str1 = \"অনেক\"\n",
        "  for i in range(num_generated):\n",
        "    prediction = model.predict(x=np.array(word_idxs)) #print dimension\n",
        "    max_word = prediction[-1].argsort()[-10:][::-1]\n",
        "    #print(max_word)\n",
        "    j=1\n",
        "    for idx in max_word:\n",
        "      word_idxs.append(idx)\n",
        "      Distance = levenshtein_ratio_and_distance(Str1,idx2word(idx))\n",
        "      Ratio = levenshtein_ratio_and_distance(Str1,idx2word(idx),ratio_calc = True)\n",
        "      print(\"Max word %d : %s \" % (j,idx2word(idx)))\n",
        "      print(\"Distance : %s And Ratio : %s \" % (Distance,Ratio))\n",
        "      j+=1\n",
        "    #print(word_idxs)\n",
        "  return ' '.join(idx2word(idx) for idx in word_idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLaXzWDdj0yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#para = \"* শারাদিন  আজ বৃতি । রাতে  ঝর হাওয়া বএ যেতে পারে ।\"\n",
        "para = \"* শারাদিন\"\n",
        "# using split() \n",
        "# to extract words from string \n",
        "res = para.split()  \n",
        "# printing result \n",
        "print (\"The list of words is : \" +  str(res)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB_6CuBSEKgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,len(res)-1):\n",
        "  print(i)\n",
        "  word = res[i]\n",
        "  print(word) \n",
        "  word2 = res[i+1]\n",
        "  print(word2) \n",
        "  sample = generate_next_para(word,word2)\n",
        "  print('%s -> %s' % (text, sample))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}